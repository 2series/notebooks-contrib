{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## Introduction to Dask cuDF\n",
    "#### By Paul Hendricks\n",
    "-------\n",
    "\n",
    "In this notebook, we will show how to work with cuDF DataFrames distributed across multiple GPUs using Dask.\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "* [Introduction to Dask cuDF](#introduction)\n",
    "* [Setup](#setup)\n",
    "* [Dask cuDF Series Basics](#series)\n",
    "* [Dask cuDF DataFrame Basics](#dataframes)\n",
    "* [Input/Output](#io)\n",
    "* [Dask cuDF API](#daskcudfapi)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Setup\n",
    "\n",
    "This notebook was tested using the following Docker containers:\n",
    "\n",
    "* `rapidsai/rapidsai-dev-nightly:0.10-cuda10.0-devel-ubuntu18.04-py3.7` container from [DockerHub](https://hub.docker.com/r/rapidsai/rapidsai-nightly)\n",
    "\n",
    "This notebook was run on the NVIDIA GV100 GPU. Please be aware that your system may be different and you may need to modify the code or install packages to run the below examples. \n",
    "\n",
    "If you think you have found a bug or an error, please file an issue here: https://github.com/rapidsai/notebooks-contrib/issues\n",
    "\n",
    "Before we begin, let's check out our hardware setup by running the `nvidia-smi` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see what CUDA version we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Dask cudf DataFrame from Dask DataFrame (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; print('NumPy Version:', np.__version__)\n",
    "import pandas as pd; print('Pandas Version:', pd.__version__)\n",
    "\n",
    "\n",
    "pandas_df = pd.DataFrame({'a': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                          'b': [0.0, 0.1, 0.2, None, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]})\n",
    "print(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask; print('Dask Version:', dask.__version__)\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "dask_df = dd.from_pandas(pandas_df, npartitions=8)\n",
    "dask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_cudf; print('Dask cuDF Version:', dask_cudf.__version__)\n",
    "\n",
    "\n",
    "ddf = dask_cudf.from_dask_dataframe(dask_df)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Dask cudf DataFrame from cuDF DataFrame (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pandas_df = pd.DataFrame({'a': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                          'b': [0.0, 0.1, 0.2, None, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]})\n",
    "print(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf; print('cuDF Version:', cudf.__version__)\n",
    "\n",
    "\n",
    "df = cudf.from_pandas(pandas_df)\n",
    "# df = cudf.DataFrame.from_pandas(pandas_df)  # alternative\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dask_cudf.from_cudf(df, npartitions=8)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting a Dask cuDF DataFrame (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ddf.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ddf.compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"io\"></a>\n",
    "## Input/Output (coming soon!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing and Loading CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"daskcudfapi\"></a>\n",
    "## Dask cuDF API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Rows or Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame({'a': np.arange(0, 100).astype(np.int64), \n",
    "                     'b': np.arange(100, 0, -1).astype(np.float32), \n",
    "                     'c': np.arange(100, 200).astype(np.float32)})\n",
    "ddf = dask_cudf.from_cudf(df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.iloc[:, ['a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.iloc[:, ['a', 'b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Rows or Columns (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame({'a': np.arange(0, 100).astype(np.float32), \n",
    "                     'b': np.arange(100, 0, -1).astype(np.float32), \n",
    "                     'c': np.arange(100, 200).astype(np.float32)})\n",
    "ddf = dask_cudf.from_cudf(df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf.drop('a', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining New Columns (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame({'a': np.arange(0, 100).astype(np.float32), \n",
    "                     'b': np.arange(100, 0, -1).astype(np.float32), \n",
    "                     'c': np.arange(100, 200).astype(np.float32)})\n",
    "ddf = dask_cudf.from_cudf(df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf['d'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data  (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame({'a': [0, None, 2, 3, 4, 5, 6, 7, 8, None, 10],\n",
    "                     'b': [0.0, 0.1, 0.2, None, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], \n",
    "                     'c': [0.0, 0.1, None, None, 0.4, 0.5, None, 0.7, 0.8, 0.9, 1.0]})\n",
    "ddf = dask_cudf.from_cudf(df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ddf.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ddf = ddf.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_ddf.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Indexing (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "                     'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "                     'c': np.arange(0, 100).astype(np.int32), \n",
    "                     'd': np.arange(100, 0, -1).astype(np.int32)})\n",
    "ddf = dask_cudf.from_cudf(df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ddf['a'] == 2\n",
    "subset = ddf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting Data (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "                     'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "                     'c': np.arange(0, 100).astype(np.int32), \n",
    "                     'd': np.arange(100, 0, -1).astype(np.int32)})\n",
    "ddf = dask_cudf.from_cudf(df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ddf.sort_values('d').compute()\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = ddf.sort_values('c', ascending=False).compute()\n",
    "# print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ddf.sort_values(['a', 'b']).compute()\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = ddf.sort_values(['a', 'b'], ascending=False).compute()\n",
    "# print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = ddf.sort_values(['a', 'b'], ascending=[False, True]).compute()\n",
    "# print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Operations (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "                     'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "                     'c': np.arange(0, 100).astype(np.int32), \n",
    "                     'd': np.arange(100, 0, -1).astype(np.int32)})\n",
    "ddf = dask_cudf.from_cudf(df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['a'].sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogramming (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "                     'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "                     'c': np.arange(0, 100).astype(np.int32), \n",
    "                     'd': np.arange(100, 0, -1).astype(np.int32)})\n",
    "ddf = dask_cudf.from_cudf(df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ddf['a'].value_counts().compute()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenations (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "                      'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "                      'c': np.arange(0, 100).astype(np.int32), \n",
    "                      'd': np.arange(100, 0, -1).astype(np.int32)})\n",
    "df2 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "                      'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "                      'c': np.arange(0, 100).astype(np.int32), \n",
    "                      'd': np.arange(100, 0, -1).astype(np.int32)})\n",
    "ddf1 = dask_cudf.from_cudf(df1, npartitions=8)\n",
    "ddf2 = dask_cudf.from_cudf(df2, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dask_cudf.concat([ddf1, ddf2], axis=0)\n",
    "ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "#                       'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "#                       'c': np.arange(0, 100).astype(np.int32), \n",
    "#                       'd': np.arange(100, 0, -1).astype(np.int32)})\n",
    "# df2 = cudf.DataFrame({'e': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "#                       'f': np.random.randint(2, size=100).astype(np.int32), \n",
    "#                       'g': np.arange(0, 100).astype(np.int32), \n",
    "#                       'h': np.arange(100, 0, -1).astype(np.int32)})\n",
    "# ddf1 = dask_cudf.from_cudf(df1, npartitions=8)\n",
    "# ddf2 = dask_cudf.from_cudf(df2, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf = dask_cudf.concat([ddf1, ddf2], axis=1)\n",
    "# ddf.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joins (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "                      'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "                      'c': np.arange(0, 100).astype(np.int32), \n",
    "                      'd': np.arange(100, 0, -1).astype(np.int32)})\n",
    "df2 = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "                      'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "                      'e': np.arange(0, 100).astype(np.int32), \n",
    "                      'f': np.arange(100, 0, -1).astype(np.int32)})\n",
    "ddf1 = dask_cudf.from_cudf(df1, npartitions=8)\n",
    "ddf2 = dask_cudf.from_cudf(df2, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1.merge(ddf2, on=['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1.merge(ddf2, on=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_cudf.DataFrame.merge(ddf1, ddf2, on=['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_cudf.DataFrame.merge(ddf1, ddf2, on=['a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appends (coming soon!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupbys (coming soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame({'a': np.repeat([0, 1, 2, 3], 25).astype(np.int32), \n",
    "                     'b': np.random.randint(2, size=100).astype(np.int32), \n",
    "                     'c': np.arange(0, 100).astype(np.int32), \n",
    "                     'd': np.arange(100, 0, -1).astype(np.int32)})\n",
    "ddf = dask_cudf.from_cudf(df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ddf.groupby('a').sum().compute()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ddf.groupby(['a', 'b']).sum().compute().to_pandas()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding (coming soon!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we showed how to work with cuDF DataFrames distributed across multiple GPUs using Dask.\n",
    "\n",
    "To learn more about RAPIDS, be sure to check out: \n",
    "\n",
    "* [Open Source Website](http://rapids.ai)\n",
    "* [GitHub](https://github.com/rapidsai/)\n",
    "* [Press Release](https://nvidianews.nvidia.com/news/nvidia-introduces-rapids-open-source-gpu-acceleration-platform-for-large-scale-data-analytics-and-machine-learning)\n",
    "* [NVIDIA Blog](https://blogs.nvidia.com/blog/2018/10/10/rapids-data-science-open-source-community/)\n",
    "* [Developer Blog](https://devblogs.nvidia.com/gpu-accelerated-analytics-rapids/)\n",
    "* [NVIDIA Data Science Webpage](https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
